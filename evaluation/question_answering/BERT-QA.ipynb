{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERT-QA.ipynb","provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyPueARoMAgjqUtWdqaCOU0+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"EuFs07mSEKN2"},"source":["#Imports"]},{"cell_type":"code","metadata":{"id":"snlXqQXwEG9m"},"source":["!git clone https://github.com/deepmind/xquad.git\n","!pip install --quiet transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gAoxVfkWEee4"},"source":["import json\n","import numpy as np\n","\n","from transformers import (AutoTokenizer, \n","  AutoModelForQuestionAnswering, \n","  AdamW,\n"," get_linear_schedule_with_warmup,\n"," DistilBertTokenizerFast)\n"," \n","\n","import torch \n","import torch.nn as nn\n","from torch.utils.data import DataLoader\n","\n","from tqdm import tqdm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z1Tzjex0Eput","executionInfo":{"status":"ok","timestamp":1619789266783,"user_tz":-180,"elapsed":1863,"user":{"displayName":"Darius Catrina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhYmUEbSp2qDbXA23NErln5inqk08HljyoY2zpo=s64","userId":"10258321120719255878"}},"outputId":"b88f37bc-688f-4ef6-c402-25369fc1003d"},"source":["# running the model on to the gpu if it is possibile for better performance\n","\n","if torch.cuda.is_available():\n","  device = torch.device('cuda')\n","  print('Running on gpu')\n","else:\n","    device = torch.device('cpu')\n","    print('Running on cpu')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Running on gpu\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fVBBO5T2Esva"},"source":["#Data"]},{"cell_type":"markdown","metadata":{"id":"zY4Yhfi1nvp1"},"source":["Splitting the raw data into training, evaluation and test data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d00etAjnEsXG","executionInfo":{"status":"ok","timestamp":1619789267857,"user_tz":-180,"elapsed":1062,"user":{"displayName":"Darius Catrina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhYmUEbSp2qDbXA23NErln5inqk08HljyoY2zpo=s64","userId":"10258321120719255878"}},"outputId":"9e32bb40-b430-4b26-b450-67dbc267ffce"},"source":["path = 'xquad/'\n","file = 'xquad.ro.json'\n","\n","with open(path + file) as f:\n","    squad_dict = json.load(f)\n","\n","\n","train_data = {\"data\": squad_dict[\"data\"][:40], \"version\": squad_dict[\"version\"]}\n","valid_data = {\"data\": squad_dict[\"data\"][40:44], \"version\": squad_dict[\"version\"]}\n","test_data = {\"data\": squad_dict[\"data\"][44:], \"version\": squad_dict[\"version\"]}\n","\n","with open(\"train_ro_quad.json\", \"w\") as f:\n","    json.dump(train_data, f)\n","\n","with open(\"valid_ro_quad.json\", \"w\") as f:\n","    json.dump(valid_data, f)\n","\n","with open(\"test_ro_quad.json\", \"w\") as f:\n","    json.dump(test_data, f)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["dict_keys(['paragraphs', 'title'])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7IJTFV0VzJsx"},"source":["Reading the xquad - dataset"]},{"cell_type":"code","metadata":{"id":"rvpJF8n7FYxM"},"source":["def read_squad(path):\n","    # open JSON file and load intro dictionary\n","    with open(path, 'rb') as f:\n","        squad_dict = json.load(f)\n","\n","    # initialize lists for contexts, questions, and answers\n","    contexts = []\n","    questions = []\n","    answers = []\n","    # iterate through all data in squad data\n","    for group in squad_dict['data']:\n","        for passage in group['paragraphs']:\n","            context = passage['context']\n","            for qa in passage['qas']:\n","                question = qa['question']\n","                # check if we need to be extracting from 'answers' or 'plausible_answers'\n","                if 'plausible_answers' in qa.keys():\n","                    access = 'plausible_answers'\n","                else:\n","                    access = 'answers'\n","                for answer in qa[access]:\n","                    # append data to lists\n","                    contexts.append(context)\n","                    questions.append(question)\n","                    answers.append(answer)\n","    # return formatted data lists\n","    return contexts, questions, answers\n","\n","\n","def add_end_idx(answers, contexts):\n","    for answer, context in zip(answers, contexts):\n","        gold_text = answer['text']\n","        start_idx = answer['answer_start']\n","        end_idx = start_idx + len(gold_text)\n","\n","        # sometimes squad answers are off by a character or two â€“ fix this\n","        if context[start_idx:end_idx] == gold_text:\n","            answer['answer_end'] = end_idx\n","        elif context[start_idx-1:end_idx-1] == gold_text:\n","            answer['answer_start'] = start_idx - 1\n","            answer['answer_end'] = end_idx - 1     # When the gold label is off by one character\n","        elif context[start_idx-2:end_idx-2] == gold_text:\n","            answer['answer_start'] = start_idx - 2\n","            answer['answer_end'] = end_idx - 2     # When the gold label is off by two characters\n","\n","\n","def add_token_positions(encodings, answers):\n","    start_positions = []\n","    end_positions = []\n","    for i in range(len(answers)):\n","        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n","        end_positions.append(encodings.char_to_token(i, answers[i]['answer_end'] - 1))\n","\n","        # if start position is None, the answer passage has been truncated\n","        if start_positions[-1] is None:\n","            start_positions[-1] = 511\n","        if end_positions[-1] is None:\n","            end_positions[-1] = 511\n","\n","    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dXTYitu9zADR"},"source":["class SquadDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings):\n","        self.encodings = encodings\n","\n","    def __getitem__(self, idx):\n","        return {key: val[idx] for key, val in self.encodings.items()}\n","\n","    def __len__(self):\n","        return len(self.encodings.input_ids)\n","\n","\n","def load_dataset(file, tokenizer, batch_size):\n","    contexts, questions, answers = read_squad(file)\n","    add_end_idx(answers, contexts)\n","    encodings = tokenizer(contexts, questions, truncation=True, padding=True, max_length=512, return_tensors=\"pt\")\n","    add_token_positions(encodings, answers)\n","\n","    dataset = SquadDataset(encodings)\n","\n","    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n","\n","    return loader\n","\n","\n","def load_datasets(train_file, valid_file, test_file, tokenizer, batch_size):\n","    train_loader = load_dataset(train_file, tokenizer, batch_size)\n","    valid_loader = load_dataset(valid_file, tokenizer, 1)\n","    test_loader = load_dataset(test_file, tokenizer, 1)\n","\n","    return train_loader, valid_loader, test_loader"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"buTmLGOB9QRG"},"source":["#Global"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"haK_uFOH9LXO","executionInfo":{"status":"ok","timestamp":1619789282221,"user_tz":-180,"elapsed":8187,"user":{"displayName":"Darius Catrina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhYmUEbSp2qDbXA23NErln5inqk08HljyoY2zpo=s64","userId":"10258321120719255878"}},"outputId":"8197696c-d26e-48bc-8afb-a8cfbb08f7b8"},"source":["tokenizer = AutoTokenizer.from_pretrained('dumitrescustefan/bert-base-romanian-cased-v1')\n","\n","model = AutoModelForQuestionAnswering.from_pretrained(\"dumitrescustefan/bert-base-romanian-cased-v1\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at dumitrescustefan/bert-base-romanian-cased-v1 were not used when initializing BertForQuestionAnswering: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at dumitrescustefan/bert-base-romanian-cased-v1 and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"uhcdQYZ78hUy"},"source":["#Utils for testing/evaluation"]},{"cell_type":"code","metadata":{"id":"mwcMwwoh7sbz"},"source":["import re\n","import string\n","import torch\n","\n","\n","def normalize_text(s):\n","    def remove_articles(text):\n","        regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n","        return re.sub(regex, \" \", text)\n","\n","    def white_space_fix(text):\n","        return \" \".join(text.split())\n","\n","    def remove_punc(text):\n","        exclude = set(string.punctuation)\n","        return \"\".join(ch for ch in text if ch not in exclude)\n","\n","    def lower(text):\n","        return text.lower()\n","\n","    return white_space_fix(remove_articles(remove_punc(lower(s))))\n","\n","\n","def compute_exact_match(prediction, truth):\n","    return int(normalize_text(prediction) == normalize_text(truth))\n","\n","\n","def compute_f1(prediction, truth):\n","    pred_tokens = normalize_text(prediction).split()\n","    truth_tokens = normalize_text(truth).split()\n","\n","    # if either the prediction or the truth is no-answer then f1 = 1 if they agree, 0 otherwise\n","    if len(pred_tokens) == 0 or len(truth_tokens) == 0:\n","        return int(pred_tokens == truth_tokens)\n","\n","    common_tokens = set(pred_tokens) & set(truth_tokens)\n","\n","    # if there are no common tokens then f1 = 0\n","    if len(common_tokens) == 0:\n","        return 0\n","\n","    prec = len(common_tokens) / len(pred_tokens)\n","    rec = len(common_tokens) / len(truth_tokens)\n","\n","    return 2 * (prec * rec) / (prec + rec)\n","\n","\n","def get_gold_answers(example):\n","    \"\"\"helper function that retrieves all possible true answers from a squad2.0 example\"\"\"\n","\n","    gold_answers = [answer[\"text\"] for answer in example.answers if answer[\"text\"]]\n","\n","    # if gold_answers doesn't exist it's because this is a negative example -\n","    # the only correct answer is an empty string\n","    if not gold_answers:\n","        gold_answers = [\"\"]\n","\n","    return gold_answers\n","\n","\n","def compute_scores(inputs, start_logits, end_logits, gold_start, gold_end, tokenizer):\n","    answer_start = torch.argmax(start_logits)\n","    answer_end = torch.argmax(end_logits) + 1\n","\n","    prediction = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs[0][answer_start:answer_end]))\n","    gold_answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs[0][gold_start:gold_end + 1]))\n","\n","    # print(f\"Prediction: {prediction}\")\n","    # print(f\"True Answers: {gold_answer}\")\n","\n","    em_score = compute_exact_match(prediction, gold_answer)\n","    f1_score = compute_f1(prediction, gold_answer)\n","\n","    # print(f\"EM: {em_score} \\t F1: {f1_score}\")\n","\n","    return em_score, f1_score"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RbX8h4BN6Xb6"},"source":["#Training"]},{"cell_type":"code","metadata":{"id":"_GHYChD6zSBQ"},"source":["epochs = 5\n","batch_size = 3\n","learning_rate = 5e-5\n","\n","\n","train_loader, valid_loader, _ = load_datasets(\"train_ro_quad.json\",\n","                                              \"valid_ro_quad.json\",\n","                                              \"test_ro_quad.json\",\n","                                              tokenizer,\n","                                              batch_size)\n","\n","# move model over to detected device\n","model.to(device)\n","# activate training mode of model\n","model.train()\n","# initialize adam optimizer with weight decay (reduces chance of overfitting)\n","optim = AdamW(model.parameters(), lr=learning_rate)\n","\n","best_f1 = -1\n","scheduler = get_linear_schedule_with_warmup(optim,\n","                                            num_warmup_steps=len(train_loader),\n","                                            num_training_steps=len(train_loader) * epochs)\n","\n","for epoch in range(epochs):\n","    # set model to train mode\n","    model.train()\n","    total_loss = 0\n","    # setup loop (we use tqdm for the progress bar)\n","    loop = tqdm(train_loader, leave=True)\n","    for i, batch in enumerate(loop):\n","        # initialize calculated gradients (from prev step)\n","        optim.zero_grad()\n","        # pull all the tensor batches required for training\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        start_positions = batch['start_positions'].to(device)\n","        end_positions = batch['end_positions'].to(device)\n","        # train model on batch and return outputs (incl. loss)\n","        outputs = model(input_ids, attention_mask=attention_mask,\n","                        start_positions=start_positions,\n","                        end_positions=end_positions)\n","\n","        # extract loss\n","        loss = outputs[0]\n","        total_loss += loss.item()\n","        # calculate loss for every parameter that needs grad update\n","        loss.backward()\n","        # update parameters\n","        optim.step()\n","        scheduler.step()\n","        # print relevant info to progress bar\n","        loop.set_description(f'Epoch {epoch}')\n","        loop.set_postfix(loss=total_loss / (i + 1))\n","\n","    total_em = 0\n","    total_f1 = 0\n","    model.eval()\n","    loop = tqdm(valid_loader, leave=True)\n","    for i, batch in enumerate(loop):\n","        # pull all the tensor batches required for training\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        # train model on batch and return outputs (incl. loss)\n","        outputs = model(input_ids, attention_mask=attention_mask)\n","        # extract loss\n","        em_score, f1_score = compute_scores(input_ids,\n","                                            outputs.start_logits, outputs.end_logits,\n","                                            batch[\"start_positions\"], batch[\"end_positions\"],\n","                                            tokenizer)\n","\n","        total_em += em_score\n","        total_f1 += f1_score\n","\n","        # print relevant info to progress bar\n","        loop.set_description(f'Epoch {epoch}, EM {total_em / (i + 1)}, F1 {total_f1 / (i + 1)}')\n","\n","    if total_f1 / len(loop) > best_f1:\n","        print(f\"Best checkpoint found: {best_f1} -> {total_f1 / len(loop)}\")\n","        torch.save(model, \"model.pt\")\n","        best_f1 = total_f1 / len(loop)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"69e53SYZAaGj"},"source":["#Testing"]},{"cell_type":"code","metadata":{"id":"dxS_fzcSAXf7"},"source":["model = torch.load(\"model.pt\", map_location=device)\n","model.to(device)\n","\n","_, _, test_loader = load_datasets(\"train_ro_quad.json\",\n","                                  \"valid_ro_quad.json\",\n","                                  \"test_ro_quad.json\",\n","                                  tokenizer,\n","                                  1)\n","\n","total_em = 0\n","total_f1 = 0\n","model.eval()\n","loop = tqdm(test_loader, leave=True)\n","for i, batch in enumerate(loop):\n","    # pull all the tensor batches required for training\n","    input_ids = batch['input_ids'].to(device)\n","    attention_mask = batch['attention_mask'].to(device)\n","    # train model on batch and return outputs (incl. loss)\n","    outputs = model(input_ids, attention_mask=attention_mask)\n","    # extract loss\n","    em_score, f1_score = compute_scores(input_ids,\n","                                        outputs.start_logits, outputs.end_logits,\n","                                        batch[\"start_positions\"], batch[\"end_positions\"],\n","                                        tokenizer)\n","\n","    total_em += em_score\n","    total_f1 += f1_score\n","\n","    # print relevant info to progress bar\n","    loop.set_description(f'EM {total_em / (i + 1)}, F1 {total_f1 / (i + 1)}')\n","\n","print(f'EM {total_em / (i + 1)}, F1 {total_f1 / (i + 1)}')"],"execution_count":null,"outputs":[]}]}