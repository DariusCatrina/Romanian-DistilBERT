{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERT-SA(neg/poz).ipynb","provenance":[],"collapsed_sections":["9sxhFaxdbZ8K"],"toc_visible":true,"authorship_tag":"ABX9TyPV+MT4WfN5SwtVycFhjpBN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"4d17be66595d4b999e6fa01ff57830a6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4efe6e86dfcd435d9600247482797d58","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_cb5008206c074e28a3b07d746296ce45","IPY_MODEL_e4854da28e5b4752871d7db75624d13a"]}},"4efe6e86dfcd435d9600247482797d58":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cb5008206c074e28a3b07d746296ce45":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c64dfb0dd1ad4fd8af4e4ec64a3530dd","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":385,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":385,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e37aae2151b8461eb820ef4123287566"}},"e4854da28e5b4752871d7db75624d13a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a125a8554d654dca9e935d83cf43f8d8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 385/385 [00:00&lt;00:00, 1.94kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bfc753bd89494ad6bc61390e08240fed"}},"c64dfb0dd1ad4fd8af4e4ec64a3530dd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e37aae2151b8461eb820ef4123287566":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a125a8554d654dca9e935d83cf43f8d8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bfc753bd89494ad6bc61390e08240fed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e3286cc1a3bb4dac939b3d85beb8e561":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_59a311bb41f4462d8b234e2839fa69d1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_48ea08e26859479987234e3c211cf77f","IPY_MODEL_bfeb434165dc4d35bcce5aef19ec6bfc"]}},"59a311bb41f4462d8b234e2839fa69d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"48ea08e26859479987234e3c211cf77f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_465b0618c59a403f861c983fefb402de","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":500386589,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":500386589,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2a3125e6880d499baad4b7482866731f"}},"bfeb434165dc4d35bcce5aef19ec6bfc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_067b5f59257643d7b190177eff72284a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 500M/500M [00:09&lt;00:00, 52.0MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5d22c699466d496da08e30ecde92e204"}},"465b0618c59a403f861c983fefb402de":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2a3125e6880d499baad4b7482866731f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"067b5f59257643d7b190177eff72284a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5d22c699466d496da08e30ecde92e204":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"vey7BCoMbSmZ"},"source":["#Imports"]},{"cell_type":"code","metadata":{"id":"20tDJxVwOewT"},"source":["!pip install --quiet transformers\n","!git clone https://github.com/ancatache/LaRoSeDa.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yAL5C9lJOsKS","executionInfo":{"status":"ok","timestamp":1618592641075,"user_tz":-180,"elapsed":6659,"user":{"displayName":"Darius Catrina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhYmUEbSp2qDbXA23NErln5inqk08HljyoY2zpo=s64","userId":"10258321120719255878"}},"outputId":"3f0df52e-ba0c-47f4-f239-f6cd96a61350"},"source":["import json\n","import numpy as np\n","from transformers import BertTokenizer, AutoModel,Adafactor\n","import torch \n","import torch.nn as nn\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","from sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score\n","\n","if torch.cuda.is_available():\n","  device = torch.device('cuda')\n","  print('Running on gpu')\n","else:\n","    device = torch.device('cpu')\n","    print('Running on cpu')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Running on gpu\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dExHDXqWPTbA","colab":{"base_uri":"https://localhost:8080/","height":115,"referenced_widgets":["4d17be66595d4b999e6fa01ff57830a6","4efe6e86dfcd435d9600247482797d58","cb5008206c074e28a3b07d746296ce45","e4854da28e5b4752871d7db75624d13a","c64dfb0dd1ad4fd8af4e4ec64a3530dd","e37aae2151b8461eb820ef4123287566","a125a8554d654dca9e935d83cf43f8d8","bfc753bd89494ad6bc61390e08240fed","e3286cc1a3bb4dac939b3d85beb8e561","59a311bb41f4462d8b234e2839fa69d1","48ea08e26859479987234e3c211cf77f","bfeb434165dc4d35bcce5aef19ec6bfc","465b0618c59a403f861c983fefb402de","2a3125e6880d499baad4b7482866731f","067b5f59257643d7b190177eff72284a","5d22c699466d496da08e30ecde92e204"]},"executionInfo":{"status":"ok","timestamp":1618592971253,"user_tz":-180,"elapsed":13406,"user":{"displayName":"Darius Catrina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhYmUEbSp2qDbXA23NErln5inqk08HljyoY2zpo=s64","userId":"10258321120719255878"}},"outputId":"5acfa4c7-45f2-4ea9-f769-8949e737c498"},"source":["# #tokenizer for tokenization of the inputs of BERT\n","tokenizer = BertTokenizer.from_pretrained(\"dumitrescustefan/bert-base-romanian-cased-v1\")\n","# #BERT model pre-trained on an romanian corpus\n","BERT = AutoModel.from_pretrained(\"dumitrescustefan/bert-base-romanian-cased-v1\")\n","\n","\n","#batch size of the data set\n","batch_size = 3\n","\n","#loss function\n","binary_cross_entropy = nn.BCELoss()\n","epochs = 3"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4d17be66595d4b999e6fa01ff57830a6","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=385.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e3286cc1a3bb4dac939b3d85beb8e561","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=500386589.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9sxhFaxdbZ8K"},"source":["#Data preparation"]},{"cell_type":"code","metadata":{"id":"m5xbmVf5PjyB"},"source":["TEST_FILE = 'LaRoSeDa/data_splitted/laroseda_test.json'\n","\n","\n","\n","#testing split:\n","testing_label   = []\n","testing_title   = []\n","testing_content = []\n","\n","\n","\n","#TESTING DATA SET\n","with open(TEST_FILE) as f:\n","  reviews = json.load(f)['reviews']\n","\n","  for i in range(len(reviews)):\n","    encoded = tokenizer(str(reviews[i]['title']), str(reviews[i]['content']))\n","    if len(encoded['input_ids']) <= 512:\n","      testing_title.append(str(reviews[i]['title']))\n","      testing_content.append(str(reviews[i]['content']))\n","      if int(reviews[i]['starRating']) >= 3:\n","        testing_label.append(int(reviews[i]['starRating']) - 2)\n","      if int(reviews[i]['starRating']) < 3:\n","        testing_label.append(int(reviews[i]['starRating']) - 1)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TNhhoZABcLSE"},"source":["TRAIN_FILE = 'LaRoSeDa/data_splitted/laroseda_train.json'\n","\n","#training split:\n","training_label   = []\n","training_title   = []\n","trinaing_content = []\n","\n","#validation split:\n","validation_label   = []\n","validation_title   = []\n","validation_content = []\n","\n","#TRAINING DATA SET\n","#validation split 15% from testing split\n","with open(TRAIN_FILE) as f:\n","  reviews = json.load(f)['reviews']\n","\n","  #validation split is 15% from testing split\n","  val_stop = int(1.5/10*len(reviews))\n","  \n","  for i in range(val_stop):\n","    #BERT accepts max length of tokens of 512\n","    encoded = tokenizer(str(reviews[i]['title']), str(reviews[i]['content']))\n","\n","    if len(encoded['input_ids']) <= 512:\n","      validation_title.append(str(reviews[i]['title']))\n","      validation_content.append(str(reviews[i]['content']))\n","      if int(reviews[i]['starRating']) >= 3:\n","        validation_label.append(int(reviews[i]['starRating']) - 2)\n","      if int(reviews[i]['starRating']) < 3:\n","        validation_label.append(int(reviews[i]['starRating']) - 1)\n","  \n","  for i in range(val_stop, len(reviews)):\n","    encoded = tokenizer(str(reviews[i]['title']), str(reviews[i]['content']))\n","\n","    if len(encoded['input_ids']) <= 512:\n","      training_title.append(str(reviews[i]['title']))\n","      trinaing_content.append(str(reviews[i]['content']))\n","      if int(reviews[i]['starRating']) >= 3:\n","        training_label.append(int(reviews[i]['starRating']) - 2)\n","      if int(reviews[i]['starRating']) < 3:\n","        training_label.append(int(reviews[i]['starRating']) - 1)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pWoTam6scUuP"},"source":["training_batch = tokenizer(training_title, training_content,add_special_tokens=True,padding=True,truncation=True,max_length=512,return_tensors='pt')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"T64_GvoOchLy"},"source":["train_data = TensorDataset(training_batch['input_ids'], training_batch['attention_mask'],training_batch['token_type_ids'],torch.tensor(training_label))\n","train_dataloader = DataLoader(train_data, batch_size=batch_size)\n","\n","\n","val_data = TensorDataset(validation_batch['input_ids'], validation_batch['attention_mask'],validation_batch['token_type_ids'],torch.tensor(validation_label))\n","val_dataloader = DataLoader(val_data, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qZrC17LjwmU2"},"source":["#Model Preparation"]},{"cell_type":"code","metadata":{"id":"TRSxwa4IPuhd"},"source":["#the model which will be fine-tunned\n","\n","class BERT_Model(nn.Module):\n","\n","  def __init__(self, bert):\n","\n","    super(BERT_Model, self).__init__()\n","    self.bert = bert\n","\n","    #fine-tunned layer: pooled_layer -> dropout layer -> relu -> last layer -> softmax\n","    self.dropout = nn.Dropout(0.2)\n","    self.relu = nn.LeakyReLU()\n","    self.layer = nn.Linear(768, 1)\n","    self.sigmoid = nn.Sigmoid()\n","\n","\n","  def forward_pass(self, id, mask, token_type_id):\n","\n","    pooled_layer = self.bert(id, attention_mask=mask, token_type_ids=token_type_id)[1]\n","    x = self.dropout(pooled_layer)\n","    x = self.relu(x)\n","    x = self.layer(x)\n","    x = self.sigmoid(x)\n","\n","    return x\n","\n","\n","#putting the model on to GPU\n","\n","model = BERT_Model(BERT)\n","model = model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t0Z0Z19Twt5V"},"source":["Training function"]},{"cell_type":"code","metadata":{"id":"2emiwsieweBM"},"source":["#variables for the scheduler \n","num_warmup_steps = int(len(train_dataloader)/ batch_size)\n","num_train_steps = int(len(train_dataloader) * epochs / batch_size)\n","\n","\n","optimizer = AdamW(model.parameters(), lr=3e-5)\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps, num_train_steps)\n","\n","#... trained on every epoch ...\n","def train():\n","\n","  #function to put the model in to straining state\n","  model.train()\n","  #toatal loss of the epoch\n","  total_loss = 0\n","\n","  for step, batch in enumerate(train_dataloader):\n","    #moving the data on same gpu as the model\n","    batch = [sample.to(device) for sample in batch]\n","    ids, masks, tokens, labels = batch\n","\n","    model.zero_grad()\n","\n","    #output of the model\n","\n","    y = model.forward_pass(ids, masks, tokens)\n","    \n","    labels = labels.to(torch.float32)\n","    y = y.to(torch.float32)\n","    \n","    loss = binary_cross_entropy(y, labels) \n","    total_loss+=loss\n","    \n","\n","    #cliping the gradients\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), 2.0)\n","\n","    #backpropagation stage\n","    loss.backward()\n","    optimizer.step()\n","    scheduler.step()\n","\n","    #moving the output on cpu to save memory\n","    y = y.detach().cpu().numpy()\n","\n","    if step % 100 == 0 and not step == 0:\n","      print(' Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n","      print(' Total loss over this batch: {}'.format(loss))\n","      print('-------')\n","\n","  return total_loss/len(train_dataloader)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jvaac_4ow_Ql"},"source":["Evaluation function"]},{"cell_type":"code","metadata":{"id":"nyb59-uPw5jt"},"source":["def convert(outputs):\n","  for output in outputs:\n","    if output[0] >= 0.5:\n","      output[0] = 1\n","    elif output[0] < 0.5:\n","      output[0] = 0\n","\n","\n","\n","#evaluation function \n","def evaluate():\n","  print('Evaluation...')\n","\n","  total_loss = 0\n","  model.eval()\n","  test_scores = []\n","  \n","  for step, batch in enumerate(val_dataloader):\n","    \n","    batch = [sample.to(device) for sample in batch]\n","    id, mask, token, label = batch\n","\n","    with torch.no_grad():\n","\n","      output = model.forward_pass(id, mask, token)\n","\n","\n","      target = label.to(torch.float32)\n","      output = output.to(torch.float32)\n","\n","      loss = binary_cross_entropy(output, target)\n","\n","      total_loss+=loss\n","\n","      convert(output)\n","      target = target.detach().cpu().numpy()\n","      output = output.detach().cpu().numpy()\n","\n","      acc_score = accuracy_score(target,output)\n","      f_score = f1_score(target, output, average='macro')\n","\n","      if step % 50 == 0 and not step == 0:\n","        print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n","        print('  Accuracy over F1: {}'.format(acc_score/f_score))\n","\n","      test_scores.append(acc_score/f_score)\n","      \n","  return total_loss / len(val_dataloader)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qQlmP1Jo-zVU"},"source":["#Training"]},{"cell_type":"code","metadata":{"id":"yhjN-fw9xGDu"},"source":["best_loss = float('inf')\n","\n","\n","total_val_losses = []\n","total_train_losses = []\n","k = 0\n","\n","for epoch in range(epochs):\n","  k+=1\n","  print('\\n\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n","\n","\n","  train_loss = train()\n","  val_loss = evaluate()\n","\n","  #finding the best loss over the epoch to save the right model\n","  if val_loss < best_loss:\n","    best_loss = val_loss\n","    torch.save(model.state_dict(), 'saved_weights.pt') \n","\n","  total_train_losses.append(train_loss)\n","  total_val_losses.append(val_loss)\n","\n","  print(f'\\nTraining Loss: {train_loss:.3f}')\n","  print(f'Validation Loss: {val_loss:.3f}')\n","\n","  #preventing overfitting\n","  if k >= 4 and abs(total_train_losses[k - 1] - total_train_losses[k - 2]) <= 0.01 and abs(total_train_losses[k - 2] - total_train_losses[k - 3]) <= 0.01:\n","    break\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xGUXO7-oA1O4"},"source":["#Testing(Needs to be modified)"]},{"cell_type":"code","metadata":{"id":"2NewatsSQLsR"},"source":["PATH = 'saved_weights.pt'\n","model.load_state_dict(torch.load(PATH, map_location='cuda:0'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h_FdGnWNQOsn"},"source":["# testing...\n","from sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score\n","# accuracy\n","# precision\n","# recall\n","# F1(macro)\n","\n","def convert(outputs):\n","  for output in outputs:\n","    if output[0] >= 0.5:\n","      output[0] = 1\n","    elif output[0] < 0.5:\n","      output[0] = 0\n","  \n","\n","def test():\n","  print('Testing...')\n","  model.eval()\n","  total_acc = 0\n","  total_prec = 0\n","  total_rec = 0\n","  total_f1 = 0\n","\n","\n","  for step, batch in enumerate(test_dataloader):\n","\n","      batch = [sample.to(device) for sample in batch]\n","      id, mask, token, label = batch\n","\n","      with torch.no_grad():\n","        output = model.forward_pass(id, mask, token)\n","        \n","\n","        target = label.detach().cpu().numpy()\n","        output = output.detach().cpu().numpy()\n","\n","        convert(output)\n","\n","        acc_score = accuracy_score(target,output)\n","        prec_score = precision_score(target, output,average='macro')\n","        rec_score = recall_score(target, output, average='macro')\n","        f_1_score = f1_score(target, output, average=None)\n","\n","        total_acc+=acc_score\n","        total_prec+=prec_score\n","        total_rec+=rec_score\n","        total_f1+=f_1_score\n","\n","        if step % 50 == 0 and step != 0:\n","          print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(test_dataloader)))\n","          print('  Scores: {},{},{},{}'.format(total_acc/step, total_prec/step, total_rec/step, total_f1/step))\n","          print('------')\n","\n","\n","\n","  return total_acc/len(test_dataloader),total_prec/len(test_dataloader),total_rec/len(test_dataloader),total_f1/len(test_dataloader)\n","\n","\n","def testing():\n","  print('Scores: Accuracy score, Precision score, Recall score, F1 score')\n","\n","  accuracy_loss, precision_loss, recall_loss, f1_loss = test()\n","\n","  print('  Average accuracy score: {}'.format(accuracy_loss))\n","  print('  Average precision score: {}'.format(precision_loss))\n","  print('  Average recall score: {}'.format(recall_loss))\n","  print('  Average F1 score: {}'.format(f1_loss))\n","\n","\n","testing()\n","\n","\n"],"execution_count":null,"outputs":[]}]}