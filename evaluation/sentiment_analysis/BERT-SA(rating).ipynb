{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERT-SA(rating).ipynb","provenance":[],"collapsed_sections":["AjDhly8F0HdQ","dHkSY5BrAxEO","oaEAPLMT0EEV","nsOl_TSha9A0"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"d8c529c5d6534e5493fd7394e804b42e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d642a74f895a4c51bdc36395a5081bac","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6f9abc7f2cb841768082e6a64f384552","IPY_MODEL_baa839afff724601b6effa4f20616f37"]}},"d642a74f895a4c51bdc36395a5081bac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6f9abc7f2cb841768082e6a64f384552":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_cc093ed060aa42a9b33f6aa70ef74fa7","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":397396,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":397396,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_84493397a1d148558d1f987a17ae15aa"}},"baa839afff724601b6effa4f20616f37":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_202449ba73b343deb5a6fc024153ce74","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 397k/397k [00:01&lt;00:00, 343kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_192220a9fcaa4aaf8cf2b5d7497cc623"}},"cc093ed060aa42a9b33f6aa70ef74fa7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"84493397a1d148558d1f987a17ae15aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"202449ba73b343deb5a6fc024153ce74":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"192220a9fcaa4aaf8cf2b5d7497cc623":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b8e25ba92cd6441eb4c228bfa3ac256e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ac4859e5590645ddb6eec533e40f464c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ddc559ceb0d6485693403c65d00d5bed","IPY_MODEL_c6db735fc4cb4637b1b796af1916d0d4"]}},"ac4859e5590645ddb6eec533e40f464c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ddc559ceb0d6485693403c65d00d5bed":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0db94d6c9e0545bd9415a359229574ae","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":385,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":385,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3c57e17198404f5bbe940e47faf4a2c0"}},"c6db735fc4cb4637b1b796af1916d0d4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_695d276b13be4a9dbe3e0417ad849db1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 385/385 [00:00&lt;00:00, 500B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6fafa3f8857a449c87594031ba7a7a5c"}},"0db94d6c9e0545bd9415a359229574ae":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3c57e17198404f5bbe940e47faf4a2c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"695d276b13be4a9dbe3e0417ad849db1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6fafa3f8857a449c87594031ba7a7a5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ef02281c888f4bbc98d2b561498f1b5f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f31c769677814968a80fbaf0d0c76634","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_196115073b2240739823b19f60d0b3ad","IPY_MODEL_cdcab9810b9746e2a2f564cff6e6594f"]}},"f31c769677814968a80fbaf0d0c76634":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"196115073b2240739823b19f60d0b3ad":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_74d4f248569e4204bd6d43a6be0c3885","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":500386589,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":500386589,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bd4f3b2786ad454f9a3117fa81cf71fe"}},"cdcab9810b9746e2a2f564cff6e6594f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_95706d4d525842958d53f9ba7b9795a4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 500M/500M [00:16&lt;00:00, 30.7MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cb3913df8fa34d34b8fb007fd04e3854"}},"74d4f248569e4204bd6d43a6be0c3885":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"bd4f3b2786ad454f9a3117fa81cf71fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"95706d4d525842958d53f9ba7b9795a4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"cb3913df8fa34d34b8fb007fd04e3854":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"AjDhly8F0HdQ"},"source":["#Imports"]},{"cell_type":"code","metadata":{"id":"AP7ZLoYO0YPO"},"source":["!pip install --quiet transformers\n","!git clone https://github.com/ancatache/LaRoSeDa.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"idustoJ1sU8P"},"source":["import json\n","import numpy as np\n","from transformers import BertTokenizer, AutoModel,Adafactor\n","import torch \n","import torch.nn as nn\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","from sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cgy6vkm00n9d"},"source":["GPU running set-up"]},{"cell_type":"code","metadata":{"id":"gb5ejhLS0ncJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619792076365,"user_tz":-180,"elapsed":981,"user":{"displayName":"Darius Catrina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhYmUEbSp2qDbXA23NErln5inqk08HljyoY2zpo=s64","userId":"10258321120719255878"}},"outputId":"62cc1bdf-51ef-4b69-ddd5-62609da96ab3"},"source":["# running the model on to the gpu if it is possibile for better performance\n","\n","if torch.cuda.is_available():\n","  device = torch.device('cuda')\n","  print('Running on gpu')\n","else:\n","    device = torch.device('cpu')\n","    print('Running on cpu')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Running on gpu\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dHkSY5BrAxEO"},"source":["#Importnat global variables"]},{"cell_type":"code","metadata":{"id":"79ycjLttA6y8","colab":{"base_uri":"https://localhost:8080/","referenced_widgets":["d8c529c5d6534e5493fd7394e804b42e","d642a74f895a4c51bdc36395a5081bac","6f9abc7f2cb841768082e6a64f384552","baa839afff724601b6effa4f20616f37","cc093ed060aa42a9b33f6aa70ef74fa7","84493397a1d148558d1f987a17ae15aa","202449ba73b343deb5a6fc024153ce74","192220a9fcaa4aaf8cf2b5d7497cc623","b8e25ba92cd6441eb4c228bfa3ac256e","ac4859e5590645ddb6eec533e40f464c","ddc559ceb0d6485693403c65d00d5bed","c6db735fc4cb4637b1b796af1916d0d4","0db94d6c9e0545bd9415a359229574ae","3c57e17198404f5bbe940e47faf4a2c0","695d276b13be4a9dbe3e0417ad849db1","6fafa3f8857a449c87594031ba7a7a5c","ef02281c888f4bbc98d2b561498f1b5f","f31c769677814968a80fbaf0d0c76634","196115073b2240739823b19f60d0b3ad","cdcab9810b9746e2a2f564cff6e6594f","74d4f248569e4204bd6d43a6be0c3885","bd4f3b2786ad454f9a3117fa81cf71fe","95706d4d525842958d53f9ba7b9795a4","cb3913df8fa34d34b8fb007fd04e3854"]},"executionInfo":{"status":"ok","timestamp":1619792101219,"user_tz":-180,"elapsed":22216,"user":{"displayName":"Darius Catrina","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhYmUEbSp2qDbXA23NErln5inqk08HljyoY2zpo=s64","userId":"10258321120719255878"}},"outputId":"ae142a26-d69b-4270-9b58-be63801515c3"},"source":["# #tokenizer for tokenization of the inputs of BERT\n","tokenizer = BertTokenizer.from_pretrained(\"dumitrescustefan/bert-base-romanian-cased-v1\")\n","# #BERT model pre-trained on an romanian corpus\n","BERT = AutoModel.from_pretrained(\"dumitrescustefan/bert-base-romanian-cased-v1\")\n","\n","\n","#batch size of the data set\n","batch_size = 3\n","\n","#loss function\n","cross_entropy = nn.CrossEntropyLoss()\n","epochs = 10"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d8c529c5d6534e5493fd7394e804b42e","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=397396.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b8e25ba92cd6441eb4c228bfa3ac256e","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=385.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ef02281c888f4bbc98d2b561498f1b5f","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=500386589.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oaEAPLMT0EEV"},"source":["# Data preparation"]},{"cell_type":"markdown","metadata":{"id":"lpjrocxeBipZ"},"source":["Splitting the training and testing set into arrays ready for tokenization"]},{"cell_type":"markdown","metadata":{"id":"MOsWtX7WEM6k"},"source":["training && evaluation data"]},{"cell_type":"code","metadata":{"id":"Qixh3EqzETS7"},"source":["TRAIN_FILE = 'LaRoSeDa/data_splitted/laroseda_train.json'\n","\n","#training split:\n","training_label   = []\n","training_title   = []\n","trinaing_content = []\n","\n","#validation split:\n","validation_label   = []\n","validation_title   = []\n","validation_content = []\n","\n","#TRAINING DATA SET\n","#validation split 15% from testing split\n","with open(TRAIN_FILE) as f:\n","  reviews = json.load(f)['reviews']\n","\n","  #validation split is 15% from testing split\n","  val_stop = int(1.5/10*len(reviews))\n","  \n","  for i in range(val_stop):\n","    #BERT accepts max length of tokens of 512\n","    encoded = tokenizer(str(reviews[i]['title']), str(reviews[i]['content']))\n","\n","    if len(encoded['input_ids']) <= 512:\n","      validation_title.append(str(reviews[i]['title']))\n","      validation_content.append(str(reviews[i]['content']))\n","      if int(reviews[i]['starRating']) >= 3:\n","        validation_label.append(int(reviews[i]['starRating']) - 2)\n","      if int(reviews[i]['starRating']) < 3:\n","        validation_label.append(int(reviews[i]['starRating']) - 1)\n","  \n","  for i in range(val_stop, len(reviews)):\n","    encoded = tokenizer(str(reviews[i]['title']), str(reviews[i]['content']))\n","\n","    if len(encoded['input_ids']) <= 512:\n","      training_title.append(str(reviews[i]['title']))\n","      trinaing_content.append(str(reviews[i]['content']))\n","      if int(reviews[i]['starRating']) >= 3:\n","        training_label.append(int(reviews[i]['starRating']) - 2)\n","      if int(reviews[i]['starRating']) < 3:\n","        training_label.append(int(reviews[i]['starRating']) - 1)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UdrTF3SOEhy7"},"source":["Testing data..."]},{"cell_type":"code","metadata":{"id":"rleUu7x31xqk"},"source":["TEST_FILE = 'LaRoSeDa/data_splitted/laroseda_test.json'\n","\n","\n","\n","#testing split:\n","testing_label   = []\n","testing_title   = []\n","testing_content = []\n","\n","\n","\n","#TESTING DATA SET\n","with open(TEST_FILE) as f:\n","  reviews = json.load(f)['reviews']\n","\n","  for i in range(len(reviews)):\n","    encoded = tokenizer(str(reviews[i]['title']), str(reviews[i]['content']))\n","    if len(encoded['input_ids']) <= 512:\n","      testing_title.append(str(reviews[i]['title']))\n","      testing_content.append(str(reviews[i]['content']))\n","      if int(reviews[i]['starRating']) >= 3:\n","        testing_label.append(int(reviews[i]['starRating']) - 2)\n","      if int(reviews[i]['starRating']) < 3:\n","        testing_label.append(int(reviews[i]['starRating']) - 1)\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ry4KxYnwBsEl"},"source":["Tokenization of the data training set"]},{"cell_type":"code","metadata":{"id":"M41We1ZwBrUh"},"source":["training_batch = tokenizer(training_title, trinaing_content,add_special_tokens=True,padding=True,truncation=True,max_length=512,return_tensors='pt')\n","validation_batch = tokenizer(validation_title, validation_content,add_special_tokens=True,padding=True,truncation=True,max_length=512,return_tensors='pt')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z43hrX2kE6ti"},"source":["\n","Tokenization of the data training set"]},{"cell_type":"code","metadata":{"id":"6_E0XQ_eE1D7"},"source":["testing_batch = tokenizer(testing_title, testing_content,add_special_tokens=True,padding=True,truncation=True,max_length=512,return_tensors='pt')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cdbi69eGFZtg"},"source":["Tensor Loaders for training"]},{"cell_type":"code","metadata":{"id":"QHaezaQZFZaf"},"source":["train_data = TensorDataset(training_batch['input_ids'], training_batch['attention_mask'],training_batch['token_type_ids'],torch.tensor(training_label))\n","train_dataloader = DataLoader(train_data, batch_size=batch_size)\n","\n","\n","val_data = TensorDataset(validation_batch['input_ids'], validation_batch['attention_mask'],validation_batch['token_type_ids'],torch.tensor(validation_label))\n","val_dataloader = DataLoader(val_data, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P4MPyKzzFBgn"},"source":["Tensor Loaders for testing"]},{"cell_type":"code","metadata":{"id":"4eNQ2zA8FEca"},"source":["test_data = TensorDataset(testing_batch['input_ids'], testing_batch['attention_mask'],testing_batch['token_type_ids'],torch.tensor(testing_label))\n","test_dataloader = DataLoader(test_data, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rhIiNnyiHnC0"},"source":["#Model Preparation"]},{"cell_type":"code","metadata":{"id":"7mFSL4PIHo3y"},"source":["#the model which will be fine-tunned\n","\n","class BERT_Model(nn.Module):\n","\n","  def __init__(self, bert):\n","\n","    super(BERT_Model, self).__init__()\n","    self.bert = bert\n","\n","    #fine-tunned layer: pooled_layer -> dropout layer -> relu -> last layer -> softmax\n","    self.dropout = nn.Dropout(0.2)\n","    self.relu = nn.LeakyReLU()\n","    self.layer = nn.Linear(768, 4)\n","    self.softmax = nn.Softmax(dim=1)\n","\n","\n","  def forward_pass(self, id, mask, token_type_id):\n","    pooled_layer = self.bert(id, attention_mask=mask, token_type_ids=token_type_id)[1]\n","    x = self.dropout(pooled_layer)\n","    x = self.relu(x)\n","    x = self.layer(x)\n","    x = self.softmax(x)\n","\n","    return x\n","\n","\n","\n","model = BERT_Model(BERT)\n","model = model.to(device)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TeAVW3bPbFUu"},"source":["#Training"]},{"cell_type":"markdown","metadata":{"id":"cknumAYfLyUR"},"source":["TRAINING FUNCTION"]},{"cell_type":"code","metadata":{"id":"hbRWB6CjLJpd"},"source":["#variables for the scheduler \n","num_warmup_steps = int(len(train_dataloader)/ batch_size)\n","num_train_steps = int(len(train_dataloader) * epochs / batch_size)\n","\n","\n","optimizer = AdamW(model.parameters(), lr=3e-5)\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps, num_train_steps)\n","\n","#... trained on every epoch ...\n","def train():\n","\n","  #function to put the model in to straining state\n","  model.train()\n","  #toatal loss of the epoch\n","  total_loss = 0\n","\n","  for step, batch in enumerate(train_dataloader):\n","    #moving the data on same gpu as the model\n","    batch = [sample.to(device) for sample in batch]\n","    ids, masks, tokens, labels = batch\n","\n","    model.zero_grad()\n","\n","    #output of the model\n","    y = model.forward_pass(ids, masks, tokens)\n","    loss = cross_entropy(y, labels)\n","\n","    total_loss+=loss\n","\n","    #cliping the gradients\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)\n","\n","    #backpropagation stage\n","    loss.backward()\n","    optimizer.step()\n","    scheduler.step()\n","\n","    #moving the output on cpu to save memory\n","    y = y.detach().cpu().numpy()\n","\n","    if step % 100 == 0 and not step == 0:\n","      print(' Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n","      print(' Total loss over this batch: {}'.format(loss))\n","      print('-------')\n","\n","  return total_loss/len(train_dataloader)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7ZZIrMxvnJgP"},"source":["Evaluation function"]},{"cell_type":"code","metadata":{"id":"HdmkyxV_nLhG"},"source":["def convert(outputs, labels):\n","  new_output = torch.zeros(outputs.shape)\n","  new_labels = torch.zeros(outputs.shape)\n","  \n","  for j in range(len(outputs)):\n","    max = float('-inf')\n","    k = None\n","    for i in range(len(outputs[j])):\n","      if max < outputs[j][i]:\n","        max = outputs[j][i]\n","        k = i\n","\n","    new_output[j][k] = 1\n","\n","  for i in range(len(outputs)):\n","    new_labels[i][labels[i]] = 1\n","\n","  return new_output, new_labels\n","\n","\n","\n","#evaluation function \n","def evaluate():\n","  print('Evaluation...')\n","\n","  total_loss = 0\n","  model.eval()\n","  test_scores = []\n","  \n","  for step, batch in enumerate(val_dataloader):\n","    \n","    batch = [sample.to(device) for sample in batch]\n","    id, mask, token, label = batch\n","\n","    with torch.no_grad():\n","\n","      y = model.forward_pass(id, mask, token)\n","      loss = cross_entropy(y, label)\n","\n","      total_loss+=loss\n","\n","      output, target = convert(y.detach().cpu().numpy(), label)\n","      acc_score = accuracy_score(target,output)\n","      f_score = f1_score(target, output, average='macro')\n","\n","      if step % 50 == 0 and not step == 0:\n","        print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n","        print('  Accuracy over F1: {}'.format(acc_score/f_score))\n","\n","      test_scores.append(acc_score/f_score)\n","      \n","  return total_loss / len(val_dataloader)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aa9xJMQ-nVSp"},"source":["best_loss = float('inf')\n","\n","\n","total_val_losses = []\n","total_train_losses = []\n","k = 0\n","\n","for epoch in range(epochs):\n","  k+=1\n","  print('\\n\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n","  train_loss = train()\n","  val_loss = evaluate()\n","\n","  #finding the best loss over the epoch to save the right model\n","  if val_loss < best_loss:\n","    best_loss = val_loss\n","    torch.save(model.state_dict(), 'saved_weights.pt') \n","\n","  total_train_losses.append(train_loss)\n","  total_val_losses.append(val_loss)\n","\n","  print(f'\\nTraining Loss: {train_loss:.3f}')\n","  print(f'Validation Loss: {val_loss:.3f}')\n","\n","  #preventing overfitting\n","  if k >= 4 and abs(total_train_losses[k - 1] - total_train_losses[k - 2]) <= 0.01 and abs(total_train_losses[k - 2] - total_train_losses[k - 3]) <= 0.01:\n","    break\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nsOl_TSha9A0"},"source":["#Testing"]},{"cell_type":"code","metadata":{"id":"qlqGM8TS0jQJ"},"source":["\n","PATH = 'saved_weights.pt'\n","\n","model.load_state_dict(torch.load(PATH, map_location={'cuda:1':'cuda:0'}))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nMOkzppp192k"},"source":["# testing...\n","from sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score\n","# accuracy\n","# precision\n","# recall\n","# F1(macro)\n","\n","\n","def convert(outputs, labels):\n","  new_output = torch.zeros(outputs.shape)\n","  new_labels = torch.zeros(outputs.shape)\n","  \n","  for j in range(len(outputs)):\n","    max = float('-inf')\n","    k = None\n","    for i in range(len(outputs[j])):\n","      if max < outputs[j][i]:\n","        max = outputs[j][i]\n","        k = i\n","\n","    new_output[j][k] = 1\n","\n","  for i in range(len(outputs)):\n","    new_labels[i][labels[i]] = 1\n","\n","  return new_output, new_labels\n","\n","\n","\n","\n","def test():\n","  print('Testing...')\n","  model.eval()\n","  total_acc = 0\n","  total_prec = 0\n","  total_rec = 0\n","  total_f1 = 0\n","\n","\n","  for step, batch in enumerate(test_dataloader):\n","\n","      batch = [sample.to(device) for sample in batch]\n","      id, mask, token, label = batch\n","\n","      with torch.no_grad():\n","        output = model.forward_pass(id, mask, token)\n","        print(output)\n","        break\n","        output = output.detach().cpu().numpy()\n","\n","\n","        output, target = convert(output, label.detach().cpu().numpy())\n","\n","\n","        acc_score = accuracy_score(target,output)\n","        prec_score = precision_score(target, output,average='macro')\n","        rec_score = recall_score(target, output, average='macro')\n","        f_1_score = f1_score(target, output, average=None)\n","\n","        total_acc+=acc_score\n","        total_prec+=prec_score\n","        total_rec+=rec_score\n","        total_f1+=f_1_score\n","\n","        if step % 50 == 0 and step != 0:\n","          print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(test_dataloader)))\n","          print('  Scores: {},{},{},{}'.format(total_acc/step, total_prec/step, total_rec/step, total_f1/step))\n","          print('------')\n","\n","  return total_acc/len(test_dataloader),total_prec/len(test_dataloader),total_rec/len(test_dataloader),total_f1/len(test_dataloader)\n","\n","def testing():\n","  print('Scores: Accuracy score, Precision score, Recall score, F1 score')\n","\n","  accuracy_loss, precision_loss, recall_loss, f1_loss = test()\n","\n","  print('  Average accuracy score: {}'.format(accuracy_loss))\n","  print('  Average precision score: {}'.format(precision_loss))\n","  print('  Average recall score: {}'.format(recall_loss))\n","  print('  Average F1 score: {}'.format(f1_loss))\n","\n","\n","\n","testing()\n"],"execution_count":null,"outputs":[]}]}